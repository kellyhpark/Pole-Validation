{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [\n",
    "    \"canada_wildfires_2016\", \"cyclone_idai_2019\", \"ecuador_earthquake_2016\",\n",
    "    \"hurricane_harvey_2017\", \"hurricane_irma_2017\", \"hurricane_maria_2017\",\n",
    "    \"hurricane_matthew_2016\", \"italy_earthquake_aug_2016\", \"kaikoura_earthquake_2016\",\n",
    "    \"puebla_mexico_earthquake_2017\", \"srilanka_floods_2017\"\n",
    "]\n",
    "\n",
    "dataframes = {event: {} for event in events}\n",
    "\n",
    "# Loop through each event and load train, dev, and test sets\n",
    "for event in events:\n",
    "    for set_type in ['train', 'dev', 'test']:\n",
    "        file_path = f'../data/HumAID/{event}/{event}_{set_type}.tsv'\n",
    "        # Load the dataset and store it in the dictionary under the appropriate event and set type\n",
    "        dataframes[event][set_type] = pd.read_csv(file_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>728674116773904384</td>\n",
       "      <td>RT @FoothillsFCU23: In response the to the #Fo...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>729787427829612544</td>\n",
       "      <td>Redcross is offering charitable donation recei...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>730510385544085505</td>\n",
       "      <td>RT @globeandmail: Red Cross to transfer $50-mi...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>733705874594746368</td>\n",
       "      <td>Live: Emergency operations briefing on north A...</td>\n",
       "      <td>other_relevant_information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>730606066023665665</td>\n",
       "      <td>$9bn fire damage to Fort McMurray, ‘the beast’...</td>\n",
       "      <td>infrastructure_and_utility_damage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>729062171993374720</td>\n",
       "      <td>I feel sad Mom &amp;amp; I r donating money to the...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>728733841230311425</td>\n",
       "      <td>This is the best way to help. The Red Cross wi...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>730078294259961856</td>\n",
       "      <td>RT @TheGrayGroup: Donations for Fort McMurray ...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>730002964035723264</td>\n",
       "      <td>Local volleyball team members raise money to h...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>729526488366616576</td>\n",
       "      <td>These heroes brought students to their familie...</td>\n",
       "      <td>rescue_volunteering_or_donation_effort</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id                                         tweet_text  \\\n",
       "0    728674116773904384  RT @FoothillsFCU23: In response the to the #Fo...   \n",
       "1    729787427829612544  Redcross is offering charitable donation recei...   \n",
       "2    730510385544085505  RT @globeandmail: Red Cross to transfer $50-mi...   \n",
       "3    733705874594746368  Live: Emergency operations briefing on north A...   \n",
       "4    730606066023665665  $9bn fire damage to Fort McMurray, ‘the beast’...   \n",
       "..                  ...                                                ...   \n",
       "440  729062171993374720  I feel sad Mom &amp; I r donating money to the...   \n",
       "441  728733841230311425  This is the best way to help. The Red Cross wi...   \n",
       "442  730078294259961856  RT @TheGrayGroup: Donations for Fort McMurray ...   \n",
       "443  730002964035723264  Local volleyball team members raise money to h...   \n",
       "444  729526488366616576  These heroes brought students to their familie...   \n",
       "\n",
       "                                class_label  \n",
       "0    rescue_volunteering_or_donation_effort  \n",
       "1    rescue_volunteering_or_donation_effort  \n",
       "2    rescue_volunteering_or_donation_effort  \n",
       "3                other_relevant_information  \n",
       "4         infrastructure_and_utility_damage  \n",
       "..                                      ...  \n",
       "440  rescue_volunteering_or_donation_effort  \n",
       "441  rescue_volunteering_or_donation_effort  \n",
       "442  rescue_volunteering_or_donation_effort  \n",
       "443  rescue_volunteering_or_donation_effort  \n",
       "444  rescue_volunteering_or_donation_effort  \n",
       "\n",
       "[445 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['canada_wildfires_2016']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = []\n",
    "dev_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "# Iterate over each event and set type, adding the event name as a column\n",
    "for event, sets in dataframes.items():\n",
    "    for set_type, df in sets.items():\n",
    "        df['event'] = event  # Add the event name as a column\n",
    "        \n",
    "        # Append the DataFrame to the appropriate list based on the set type\n",
    "        if set_type == 'train':\n",
    "            train_dfs.append(df)\n",
    "        elif set_type == 'dev':\n",
    "            dev_dfs.append(df)\n",
    "        elif set_type == 'test':\n",
    "            test_dfs.append(df)\n",
    "\n",
    "# Concatenate the lists of DataFrames into three large DataFrames\n",
    "train_df = pd.concat(train_dfs, ignore_index=True)\n",
    "val_df = pd.concat(dev_dfs, ignore_index=True)\n",
    "test_df = pd.concat(test_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rescue_volunteering_or_donation_effort    8212\n",
       "other_relevant_information                5143\n",
       "infrastructure_and_utility_damage         4151\n",
       "sympathy_and_support                      3253\n",
       "injured_or_dead_people                    2578\n",
       "caution_and_advice                        1533\n",
       "displaced_people_and_evacuations          1496\n",
       "not_humanitarian                          1284\n",
       "requests_or_urgent_needs                  1139\n",
       "missing_or_found_people                     13\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonluong/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063d48bd94034e26be26feaa841eb6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87172732ae9943ccb58813fd8fa97a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5540477153854c5d9157ea3ef8b8632f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9848a71d44874089a4c3e0fcc7699eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3bbb2b871e4e4e8e7d18c899fdcf3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'dancing', 'cooking'],\n",
       " 'scores': [0.9938650727272034, 0.003273798618465662, 0.0028610429726541042]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']\n",
    "classifier(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
